"""
Network proximity (Z-score) computation CLI runner
--------------------------------------------------

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” HERB 2.0 â€“ STRING Human PPI ë„¤íŠ¸ì›Œí¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ,
ë‘ ë…¸ë“œ ì§‘í•©(A, B) ê°„ì˜ **Network Proximity (ê·¼ì ‘ë„)** ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
-----------
1. SQLite DB(`DB.db`)ì—ì„œ Human_PPI í…Œì´ë¸”ì„ ë¶ˆëŸ¬ì™€ NetworkX ê·¸ë˜í”„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
2. `Utils.get_ensp_ids()`ë¥¼ ì‚¬ìš©í•˜ì—¬ HERB/HBIN/HBDIS ë“±ì˜ IDë¥¼ ENSP ë…¸ë“œ ì§‘í•©ìœ¼ë¡œ ë§¤í•‘í•©ë‹ˆë‹¤.
3. `proximity_util.compute_network_distances_CPU()`ë¥¼ í˜¸ì¶œí•˜ì—¬
   - í‰ê·  ìµœë‹¨ê±°ë¦¬ (shortest path mean distance)
   - Z-score (degree-matched ëœë¤ ë„¤íŠ¸ì›Œí¬ ê¸°ë°˜)
   ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
4. ê²°ê³¼ë¥¼ ì½˜ì†”(JSON í˜•ì‹)ë¡œ ì¶œë ¥í•˜ê±°ë‚˜, `--out` ì¸ìë¥¼ ì‚¬ìš©í•˜ì—¬ JSON íŒŒì¼ë¡œ ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì¸ì ì„¤ëª…:
-----------
--db           : SQLite ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ (ê¸°ë³¸ê°’: ./Data/DB.db)
--table        : PPI í…Œì´ë¸” ì´ë¦„ (ê¸°ë³¸ê°’: Human_PPI)
--src-col      : PPI í…Œì´ë¸”ì˜ source ì»¬ëŸ¼ëª… (ê¸°ë³¸ê°’: protein1)
--tgt-col      : PPI í…Œì´ë¸”ì˜ target ì»¬ëŸ¼ëª… (ê¸°ë³¸ê°’: protein2)
--a-id         : ì²« ë²ˆì§¸ ë…¸ë“œ ì§‘í•© ì‹ë³„ì (ì˜ˆ: HERB002168)
--b-id         : ë‘ ë²ˆì§¸ ë…¸ë“œ ì§‘í•© ì‹ë³„ì (ì˜ˆ: HBDIS001345)
--random-time  : degree-matched resampling ë°˜ë³µ íšŸìˆ˜ (ê¸°ë³¸ê°’: 100)
--seed         : ëœë¤ ì‹œë“œ (ê¸°ë³¸ê°’: 42)
--workers      : ë³‘ë ¬ ì›Œì»¤ ìˆ˜ (ê¸°ë³¸ê°’: 16)
--out          : ê²°ê³¼ JSON ì €ì¥ ê²½ë¡œ (ì„ íƒì‚¬í•­)

ì°¸ê³ :
------
- ê±°ë¦¬ í–‰ë ¬ ìºì‹œëŠ” ì¦ë¶„(memmap) ë°©ì‹ìœ¼ë¡œ `./Data/Human_PPI/rows_mm.npy` ê²½ë¡œì— ìë™ ìƒì„±ë©ë‹ˆë‹¤.
- í’€ ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚°(`build_dist_matrix_from_graph`)ì€ í¬í•¨ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©°,
  ëŒ€ê·œëª¨ ì‹¤í—˜ ì‹œ í•„ìš”í•  ê²½ìš° ë³„ë„ êµ¬í˜„ ê°€ëŠ¥.
"""

#!/usr/bin/env python3
# run_proximity.py
# Network proximity (Z-score) CLI runner â€” incremental cache only version

import argparse
import json
import os
import sqlite3
from pathlib import Path

import pandas as pd
import networkx as nx
import Utils
import proximity_util as pu


# =========================================
# 1. Graph Loading
# =========================================
def load_edges_from_db(db_path, table_name="Human_PPI", source_col="protein1", target_col="protein2"):
    """DBì—ì„œ PPI ì—£ì§€ ë¡œë“œ ('9606.' ì ‘ë‘ì‚¬ ì œê±° í¬í•¨)"""
    if not Path(db_path).exists():
        raise FileNotFoundError(f"DB not found: {db_path}")

    conn = sqlite3.connect(db_path)
    query = f"SELECT {source_col}, {target_col} FROM {table_name}"
    df = pd.read_sql_query(query, conn)
    conn.close()

    def strip_prefix(x):
        if isinstance(x, str) and x.startswith("9606."):
            return x.split("9606.", 1)[-1]
        return x

    df[source_col] = df[source_col].map(strip_prefix)
    df[target_col] = df[target_col].map(strip_prefix)
    edges = list(df.itertuples(index=False, name=None))
    print(f"âœ… Loaded {len(edges):,} edges from '{table_name}' (prefix '9606.' removed)")
    return edges


def create_network_from_edges(edges):
    """ì—£ì§€ ë¦¬ìŠ¤íŠ¸ë¡œë¶€í„° networkx ê·¸ë˜í”„ ìƒì„±"""
    G = nx.Graph()
    G.add_edges_from(edges)
    print(f"âœ… Graph built: {G.number_of_nodes():,} nodes, {G.number_of_edges():,} edges")
    return G


# =========================================
# 2. Helper Functions
# =========================================
def ids_to_ensp_set(identifier: str):
    """Utils.get_ensp_ids() ë˜í¼ (ë¹ˆ ì„¸íŠ¸ ê²½ê³  í¬í•¨)"""
    ensp_ids = set(Utils.get_ensp_ids(identifier) or [])
    print(f"ğŸ” {identifier}: mapped to {len(ensp_ids)} ENSP nodes")
    if not ensp_ids:
        print(f"âš ï¸ Warning: {identifier} â†’ empty ENSP set (check mapping or DB)")
    return ensp_ids


# =========================================
# 3. Main Logic
# =========================================
def run(args):
    # 1) ê·¸ë˜í”„ ë¡œë“œ
    edges = load_edges_from_db(
        db_path=args.db,
        table_name=args.table,
        source_col=args.src_col,
        target_col=args.tgt_col,
    )
    G = create_network_from_edges(edges)

    # 2) ENSP ë…¸ë“œ ì§‘í•© ë³€í™˜
    A = ids_to_ensp_set(args.a_id)
    B = ids_to_ensp_set(args.b_id)
    if not A or not B:
        raise SystemExit("âŒ Error: Empty A/B set detected â€” check HERB/DISEASE ID validity")

    # 3) ê·¼ì ‘ë„ ê³„ì‚° (memmap incremental cache ì‚¬ìš©)
    print("â„¹ï¸ Using incremental memmap cache (./Data/Human_PPI/rows_mm.npy)")
    res = pu.compute_network_distances_CPU(
        G=G,
        dist=None,  # ì¦ë¶„ ìºì‹œ ëª¨ë“œ
        A=A,
        B=B,
        random_time=args.random_time,
        seed=args.seed,
        max_workers=args.workers,
    )

    # 4) ê²°ê³¼ ì¶œë ¥
    result = {
        "A_id": args.a_id,
        "B_id": args.b_id,
        "random_time": args.random_time,
        "seed": args.seed,
        "result": res,
    }

    print("\n==== Proximity Result ====")
    print(json.dumps(result, ensure_ascii=False, indent=2))

    # 5) ê²°ê³¼ ì €ì¥
    if args.out:
        out_path = Path(args.out)
        out_path.parent.mkdir(parents=True, exist_ok=True)
        out_path.write_text(json.dumps(result, ensure_ascii=False, indent=2))
        print(f"ğŸ’¾ Saved result to: {out_path.resolve()}")


# =========================================
# 4. CLI Parser
# =========================================
def parse_args():
    p = argparse.ArgumentParser(description="Compute network proximity (Z-score) between two node sets.")
    p.add_argument("--db", default="./Data/DB.db", help="Path to SQLite DB (default: ./Data/DB.db)")
    p.add_argument("--table", default="Human_PPI", help="Edge table name (default: Human_PPI)")
    p.add_argument("--src-col", default="protein1", help="Source column (default: protein1)")
    p.add_argument("--tgt-col", default="protein2", help="Target column (default: protein2)")
    p.add_argument("--a-id", required=True, help="A set identifier (e.g., HERB002168)")
    p.add_argument("--b-id", required=True, help="B set identifier (e.g., HBDIS001345)")
    p.add_argument("--random-time", type=int, default=100, help="Degree-matched resampling count (default: 100)")
    p.add_argument("--seed", type=int, default=42, help="Random seed (default: 42)")
    p.add_argument("--workers", type=int, default=16, help="Max worker threads (default: 16)")
    p.add_argument("--out", help="Optional: save result JSON to this path")
    return p.parse_args()


if __name__ == "__main__":
    args = parse_args()
    run(args)
